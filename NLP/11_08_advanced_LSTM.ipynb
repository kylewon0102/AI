{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3618578-29d0-4218-99cc-8104a451fb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['y' 'g' 'J' 'S' 'G']\n",
      " ['F' 'K' 'c' 'K' 'o']\n",
      " ['M' 'Y' 'A' 's' 'C']\n",
      " ['h' 'C' 'z' 'C' 'e']]\n",
      "[['G' 'S' 'J' 'g' 'y']\n",
      " ['o' 'K' 'c' 'K' 'F']\n",
      " ['C' 's' 'A' 'Y' 'M']\n",
      " ['e' 'C' 'z' 'C' 'h']]\n",
      "[50 32  9 18  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_15                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">84,480</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,708</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_16 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │         \u001b[38;5;34m5,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_15                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m84,480\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m)         │         \u001b[38;5;34m6,708\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96,388</span> (376.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m96,388\u001b[0m (376.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96,388</span> (376.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m96,388\u001b[0m (376.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.1720 - loss: 3.6180 - val_accuracy: 0.4303 - val_loss: 1.9112\n",
      "Epoch 2/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4527 - loss: 1.7127 - val_accuracy: 0.4795 - val_loss: 1.4533\n",
      "Epoch 3/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5002 - loss: 1.3536 - val_accuracy: 0.5060 - val_loss: 1.3004\n",
      "Epoch 4/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5319 - loss: 1.2055 - val_accuracy: 0.5296 - val_loss: 1.2137\n",
      "Epoch 5/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5636 - loss: 1.1102 - val_accuracy: 0.5514 - val_loss: 1.1389\n",
      "Epoch 6/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5894 - loss: 1.0255 - val_accuracy: 0.5699 - val_loss: 1.0881\n",
      "Epoch 7/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6144 - loss: 0.9677 - val_accuracy: 0.5957 - val_loss: 1.0272\n",
      "Epoch 8/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6388 - loss: 0.9007 - val_accuracy: 0.6100 - val_loss: 0.9858\n",
      "Epoch 9/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6654 - loss: 0.8420 - val_accuracy: 0.6350 - val_loss: 0.9337\n",
      "Epoch 10/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6952 - loss: 0.7888 - val_accuracy: 0.6614 - val_loss: 0.8819\n",
      "Epoch 11/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7255 - loss: 0.7367 - val_accuracy: 0.6783 - val_loss: 0.8506\n",
      "Epoch 12/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7513 - loss: 0.6845 - val_accuracy: 0.7084 - val_loss: 0.7869\n",
      "Epoch 13/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7868 - loss: 0.6241 - val_accuracy: 0.7422 - val_loss: 0.7244\n",
      "Epoch 14/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8149 - loss: 0.5650 - val_accuracy: 0.7645 - val_loss: 0.6776\n",
      "Epoch 15/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8424 - loss: 0.5182 - val_accuracy: 0.7921 - val_loss: 0.6195\n",
      "Epoch 16/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8753 - loss: 0.4525 - val_accuracy: 0.8053 - val_loss: 0.5812\n",
      "Epoch 17/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8879 - loss: 0.4170 - val_accuracy: 0.8350 - val_loss: 0.5316\n",
      "Epoch 18/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9066 - loss: 0.3768 - val_accuracy: 0.8435 - val_loss: 0.4998\n",
      "Epoch 19/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9203 - loss: 0.3322 - val_accuracy: 0.8599 - val_loss: 0.4627\n",
      "Epoch 20/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9285 - loss: 0.3109 - val_accuracy: 0.8765 - val_loss: 0.4240\n",
      "Epoch 21/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9411 - loss: 0.2726 - val_accuracy: 0.8788 - val_loss: 0.4085\n",
      "Epoch 22/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9451 - loss: 0.2555 - val_accuracy: 0.8905 - val_loss: 0.3748\n",
      "Epoch 23/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9501 - loss: 0.2313 - val_accuracy: 0.8952 - val_loss: 0.3629\n",
      "Epoch 24/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9590 - loss: 0.2100 - val_accuracy: 0.8990 - val_loss: 0.3502\n",
      "Epoch 25/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9608 - loss: 0.1949 - val_accuracy: 0.9033 - val_loss: 0.3306\n",
      "Epoch 26/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9661 - loss: 0.1780 - val_accuracy: 0.9104 - val_loss: 0.3105\n",
      "Epoch 27/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9687 - loss: 0.1663 - val_accuracy: 0.9205 - val_loss: 0.2919\n",
      "Epoch 28/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9728 - loss: 0.1501 - val_accuracy: 0.9168 - val_loss: 0.2876\n",
      "Epoch 29/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9758 - loss: 0.1371 - val_accuracy: 0.9220 - val_loss: 0.2703\n",
      "Epoch 30/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.1269 - val_accuracy: 0.9214 - val_loss: 0.2721\n",
      "Epoch 31/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9786 - loss: 0.1199 - val_accuracy: 0.9273 - val_loss: 0.2527\n",
      "Epoch 32/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9821 - loss: 0.1076 - val_accuracy: 0.9252 - val_loss: 0.2568\n",
      "Epoch 33/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9839 - loss: 0.1006 - val_accuracy: 0.9331 - val_loss: 0.2396\n",
      "Epoch 34/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9855 - loss: 0.0933 - val_accuracy: 0.9321 - val_loss: 0.2413\n",
      "Epoch 35/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9863 - loss: 0.0887 - val_accuracy: 0.9339 - val_loss: 0.2316\n",
      "Epoch 36/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.0822 - val_accuracy: 0.9395 - val_loss: 0.2142\n",
      "Epoch 37/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0720 - val_accuracy: 0.9400 - val_loss: 0.2097\n",
      "Epoch 38/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0669 - val_accuracy: 0.9407 - val_loss: 0.2063\n",
      "Epoch 39/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0639 - val_accuracy: 0.9433 - val_loss: 0.1934\n",
      "Epoch 40/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9931 - loss: 0.0581 - val_accuracy: 0.9445 - val_loss: 0.1915\n",
      "Epoch 41/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.0534 - val_accuracy: 0.9460 - val_loss: 0.1858\n",
      "Epoch 42/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0489 - val_accuracy: 0.9453 - val_loss: 0.1841\n",
      "Epoch 43/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9952 - loss: 0.0441 - val_accuracy: 0.9463 - val_loss: 0.1856\n",
      "Epoch 44/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 0.0414 - val_accuracy: 0.9508 - val_loss: 0.1702\n",
      "Epoch 45/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0364 - val_accuracy: 0.9507 - val_loss: 0.1649\n",
      "Epoch 46/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9970 - loss: 0.0345 - val_accuracy: 0.9503 - val_loss: 0.1640\n",
      "Epoch 47/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0397 - val_accuracy: 0.9526 - val_loss: 0.1589\n",
      "Epoch 48/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0299 - val_accuracy: 0.9542 - val_loss: 0.1529\n",
      "Epoch 49/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0254 - val_accuracy: 0.9555 - val_loss: 0.1497\n",
      "Epoch 50/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0246 - val_accuracy: 0.9561 - val_loss: 0.1468\n",
      "Epoch 51/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0211 - val_accuracy: 0.9576 - val_loss: 0.1423\n",
      "Epoch 52/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0187 - val_accuracy: 0.9604 - val_loss: 0.1351\n",
      "Epoch 53/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0175 - val_accuracy: 0.9584 - val_loss: 0.1356\n",
      "Epoch 54/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0203 - val_accuracy: 0.9508 - val_loss: 0.1640\n",
      "Epoch 55/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0356 - val_accuracy: 0.9548 - val_loss: 0.1500\n",
      "Epoch 56/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0202 - val_accuracy: 0.9640 - val_loss: 0.1205\n",
      "Epoch 57/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0114 - val_accuracy: 0.9660 - val_loss: 0.1172\n",
      "Epoch 58/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.9674 - val_loss: 0.1114\n",
      "Epoch 59/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.9661 - val_loss: 0.1116\n",
      "Epoch 60/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0082 - val_accuracy: 0.9671 - val_loss: 0.1084\n",
      "Epoch 61/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9669 - val_loss: 0.1089\n",
      "Epoch 62/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0081 - val_accuracy: 0.9416 - val_loss: 0.1877\n",
      "Epoch 63/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9824 - loss: 0.0649 - val_accuracy: 0.9591 - val_loss: 0.1317\n",
      "Epoch 64/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0148 - val_accuracy: 0.9668 - val_loss: 0.1060\n",
      "Epoch 65/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9688 - val_loss: 0.1015\n",
      "Epoch 66/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.9701 - val_loss: 0.0992\n",
      "Epoch 67/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9694 - val_loss: 0.0990\n",
      "Epoch 68/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9698 - val_loss: 0.0979\n",
      "Epoch 69/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9700 - val_loss: 0.0969\n",
      "Epoch 70/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9711 - val_loss: 0.0951\n",
      "Epoch 71/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9715 - val_loss: 0.0952\n",
      "Epoch 72/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9720 - val_loss: 0.0941\n",
      "Epoch 73/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9713 - val_loss: 0.0936\n",
      "Epoch 74/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9716 - val_loss: 0.0904\n",
      "Epoch 75/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9722 - val_loss: 0.0903\n",
      "Epoch 76/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9726 - val_loss: 0.0893\n",
      "Epoch 77/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9720 - val_loss: 0.0914\n",
      "Epoch 78/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.0413 - val_accuracy: 0.9472 - val_loss: 0.1663\n",
      "Epoch 79/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9950 - loss: 0.0221 - val_accuracy: 0.9661 - val_loss: 0.1113\n",
      "Epoch 80/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 0.0065 - val_accuracy: 0.9704 - val_loss: 0.0958\n",
      "Epoch 81/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9706 - val_loss: 0.0926\n",
      "Epoch 82/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9717 - val_loss: 0.0896\n",
      "Epoch 83/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9720 - val_loss: 0.0886\n",
      "Epoch 84/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9724 - val_loss: 0.0876\n",
      "Epoch 85/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9713 - val_loss: 0.0865\n",
      "Epoch 86/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9726 - val_loss: 0.0847\n",
      "Epoch 87/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9730 - val_loss: 0.0844\n",
      "Epoch 88/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9742 - val_loss: 0.0827\n",
      "Epoch 89/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9741 - val_loss: 0.0817\n",
      "Epoch 90/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9738 - val_loss: 0.0824\n",
      "Epoch 91/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9741 - val_loss: 0.0809\n",
      "Epoch 92/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9743 - val_loss: 0.0807\n",
      "Epoch 93/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9750 - val_loss: 0.0793\n",
      "Epoch 94/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9746 - val_loss: 0.0787\n",
      "Epoch 95/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9747 - val_loss: 0.0772\n",
      "Epoch 96/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9765 - val_loss: 0.0759\n",
      "Epoch 97/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9753 - val_loss: 0.0758\n",
      "Epoch 98/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9754 - val_loss: 0.0765\n",
      "Epoch 99/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 9.8065e-04 - val_accuracy: 0.9767 - val_loss: 0.0754\n",
      "Epoch 100/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 9.4703e-04 - val_accuracy: 0.9440 - val_loss: 0.1921\n",
      "Epoch 101/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9563 - loss: 0.1440 - val_accuracy: 0.9640 - val_loss: 0.1182\n",
      "Epoch 102/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9991 - loss: 0.0083 - val_accuracy: 0.9709 - val_loss: 0.0913\n",
      "Epoch 103/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9732 - val_loss: 0.0828\n",
      "Epoch 104/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9740 - val_loss: 0.0800\n",
      "Epoch 105/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9741 - val_loss: 0.0788\n",
      "Epoch 106/500\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9760 - val_loss: 0.0774\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0026\n",
      "loss: 0.0158, acc=0.9953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      " Input: TFiUi\n",
      " Est. Output: iUiFT\n",
      " expected Output: iUiFT\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      " Input: RxXte\n",
      " Est. Output: etXxR\n",
      " expected Output: etXxR\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      " Input: lcOZR\n",
      " Est. Output: RZOcl\n",
      " expected Output: RZOcl\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      " Input: sVlir\n",
      " Est. Output: rilVs\n",
      " expected Output: rilVs\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      " Input: ryJiD\n",
      " Est. Output: DiJyr\n",
      " expected Output: DiJyr\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      " Input: IhsLO\n",
      " Est. Output: OLshI\n",
      " expected Output: OLshI\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      " Input: RIUHN\n",
      " Est. Output: NHUIR\n",
      " expected Output: NHUIR\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      " Input: iejef\n",
      " Est. Output: feeei\n",
      " expected Output: fejei\n",
      " Correct: Wrong\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      " Input: uRhbN\n",
      " Est. Output: NbhRu\n",
      " expected Output: NbhRu\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      " Input: rJCpG\n",
      " Est. Output: GpCJr\n",
      " expected Output: GpCJr\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      " Input: JSRAK\n",
      " Est. Output: KARSJ\n",
      " expected Output: KARSJ\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      " Input: OEfZB\n",
      " Est. Output: BZfEO\n",
      " expected Output: BZfEO\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      " Input: JiqND\n",
      " Est. Output: DNqiJ\n",
      " expected Output: DNqiJ\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      " Input: aWDoF\n",
      " Est. Output: FoDWa\n",
      " expected Output: FoDWa\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      " Input: hCjqf\n",
      " Est. Output: fqjCh\n",
      " expected Output: fqjCh\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      " Input: QsxGK\n",
      " Est. Output: KGxsQ\n",
      " expected Output: KGxsQ\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      " Input: HwqAE\n",
      " Est. Output: EAqwH\n",
      " expected Output: EAqwH\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      " Input: cBIwt\n",
      " Est. Output: twIBc\n",
      " expected Output: twIBc\n",
      " Correct: Yes\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      " Input: ottGg\n",
      " Est. Output: gttto\n",
      " expected Output: gGtto\n",
      " Correct: Wrong\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      " Input: hKxoT\n",
      " Est. Output: ToxKh\n",
      " expected Output: ToxKh\n",
      " Correct: Yes\n",
      "\n",
      " Total Acc: 90.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "cal_len = 5 #10으로 하면 (Seq2Seq 방식) 정확도가 떨어짐 LSTM 이라\n",
    "chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "num_classes = len(chars)\n",
    "\n",
    "char_to_index = {char: idx for idx, char in enumerate(chars)}\n",
    "index_to_char = {idx: char for idx, char in enumerate(chars)}\n",
    "\n",
    "train_data = np.random.choice (list(chars), size = (10000, cal_len))\n",
    "label_data = np.flip(train_data, axis=1)\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_data_indices = np.array([[char_to_index[char] for char in seq] for seq in train_data])\n",
    "label_data_indices = np.array([[char_to_index[char] for char in seq] for seq in label_data])\n",
    "\n",
    "print(train_data[:4])\n",
    "print(label_data[:4])\n",
    "\n",
    "padded_train = pad_sequences(train_data_indices, maxlen=cal_len)\n",
    "padded_labels = pad_sequences(label_data_indices, maxlen=cal_len)\n",
    "print(padded_train[0])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_classes, 100, input_length=cal_len))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.build(input_shape=(None, 52))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience = 7, restore_best_weights = True)\n",
    "\n",
    "history= model.fit(padded_train, padded_labels, epochs=500, batch_size=32, validation_split=(0.2), callbacks=[early_stop])\n",
    "\n",
    "loss, acc = model.evaluate(padded_train, padded_labels)\n",
    "print(f\"loss: {loss:.4f}, acc={acc:.4f}\")\n",
    "\n",
    "test_data = [\"\".join(np.random.choice(list(chars), cal_len)) for _ in range(20)]\n",
    "\n",
    "expected_outputs = [s[::-1] for s in test_data]\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = len(test_data)\n",
    "\n",
    "for i, test_string in enumerate(test_data):\n",
    "    numbers = [char_to_index[char] for char in test_string]\n",
    "    array_numbers =np.array([numbers])\n",
    "    padded_numbers = pad_sequences(array_numbers, maxlen=cal_len)\n",
    "    prediction = model.predict(padded_numbers)\n",
    "    predicted_indices = np.argmax(prediction, axis=-1)[0]\n",
    "    predicted_chars = [index_to_char[idx] for idx in predicted_indices]\n",
    "    predicted_output = \"\".join(predicted_chars)\n",
    "\n",
    "    is_correct = predicted_output == expected_outputs[i]\n",
    "    if is_correct:\n",
    "        correct_predictions += 1\n",
    "    print(f\" Input: {test_string}\")\n",
    "    print(f\" Est. Output: {predicted_output}\")\n",
    "    print(f\" expected Output: {expected_outputs[i]}\")\n",
    "    print(f\" Correct: {'Yes' if is_correct else 'Wrong'}\\n\")\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\" Total Acc: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
