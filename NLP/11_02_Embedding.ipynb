{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de12bf50-243f-4d4b-99b8-3cab9cf8dc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 19:16:06.002767: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
      "(25000, 20) (25000,)\n",
      "(25000,) (25000,)\n",
      "[  65   16   38 1334   88   12   16  283    5   16 4472  113  103   32\n",
      "   15   16 5345   19  178   32]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 20\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_teset = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c67224e-f364-4b54-830e-a5c918e4358d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "\n",
    "index_to_word = {index + 3: word for word, index in word_index.items()}\n",
    "#matching the Keras style of embedding\n",
    "index_to_word[0]= \"<PAD>\"\n",
    "index_to_word[1] = \"<START>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "def decode_review(encoded_review):\n",
    "    return ' '.join([index_to_word.get(i, '?') for i in encoded_review])\n",
    "\n",
    "decoded_review = decode_review(x_train[0])\n",
    "print(decoded_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4223dccf-eb39-484d-ab05-c3a316a81500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - acc: 0.5704 - loss: 0.6852 - val_acc: 0.6982 - val_loss: 0.6153\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - acc: 0.7448 - loss: 0.5647 - val_acc: 0.7296 - val_loss: 0.5257\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.7876 - loss: 0.4663 - val_acc: 0.7448 - val_loss: 0.5029\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8137 - loss: 0.4199 - val_acc: 0.7524 - val_loss: 0.4982\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8281 - loss: 0.3910 - val_acc: 0.7544 - val_loss: 0.4988\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - acc: 0.8385 - loss: 0.3736 - val_acc: 0.7522 - val_loss: 0.5025\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - acc: 0.8473 - loss: 0.3557 - val_acc: 0.7512 - val_loss: 0.5066\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - acc: 0.8593 - loss: 0.3338 - val_acc: 0.7536 - val_loss: 0.5140\n",
      "Epoch 9/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - acc: 0.8662 - loss: 0.3221 - val_acc: 0.7492 - val_loss: 0.5184\n",
      "Epoch 10/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.8720 - loss: 0.3075 - val_acc: 0.7492 - val_loss: 0.5261\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Embedding\n",
    "print(x_train.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs =10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b3348f9-f167-4a06-8454-eecef91dcc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 행렬 모양: (10000, 8)\n",
      "'good' 임베딩: [-0.05726561  0.03438354 -0.21095692 -0.18333328 -0.19895193  0.0698124\n",
      "  0.15729015  0.00870921]\n",
      "'bad' 임베딩: [ 0.05152619  0.34251812  0.46294582  0.49180067  0.3271383  -0.18326822\n",
      " -0.31053972 -0.26370612]\n",
      "'movie' 임베딩: [-0.03207814  0.07805683  0.02683133  0.0874258   0.010656    0.17133264\n",
      " -0.03301812  0.11544038]\n",
      "'bomb' 임베딩: [ 0.10289402  0.35928193  0.36207235  0.3380123   0.41198432 -0.28671098\n",
      " -0.2687604  -0.13778044]\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "embedding_matrix = embedding_layer.get_weights()[0]\n",
    "print(\"임베딩 행렬 모양:\", embedding_matrix.shape)\n",
    "\n",
    "word_index = imdb.get_word_index()\n",
    "index_to_word = {i + 3: w for w, i in word_index.items()}\n",
    "index_to_word[0] = \"<PAD>\"; index_to_word[1] = \"<START>\"\n",
    "index_to_word[2] = \"<UNK>\"; index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "def show_vector(word):\n",
    "    idx = word_index.get(word)\n",
    "    if idx is None or idx + 3 >= embedding_matrix.shape[0]:\n",
    "        print(\"단어가 어휘사전에 없습니다.\")\n",
    "        return\n",
    "    vec = embedding_matrix[idx+3]\n",
    "    print(f\"'{word}' 임베딩:\", vec)\n",
    "\n",
    "show_vector(\"good\")\n",
    "show_vector(\"bad\")\n",
    "show_vector(\"movie\")\n",
    "show_vector(\"bomb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "048ea09c-2c7a-4b0f-aadb-a8574284c473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "Review: I absolutely loved this movie. The storyline was gripping and the characters were very well developed. The performances were outstanding and the direction was top-notch. The cinematography was beautiful and the soundtrack was perfect. This is one of the best movies I've seen in a long time and I would highly recommend it to everyone. -> Prediction: Neg (Percentage: 0.2061)\n",
      "Review: This film was an incredible journey from start to finish. The visuals were stunning and the soundtrack perfectly complemented the emotional tone of the movie. The plot was engaging and the characters were relatable and well-acted. It left a lasting impression on me and I can’t wait to watch it again. A must-see for any movie lover! -> Prediction: Pos (Percentage: 0.7189)\n",
      "Review: The movie was extremely disappointing. The plot was weak and the characters were not believable. The acting was subpar and the film dragged on far too long. I wouldn't recommend this movie. -> Prediction: Neg (Percentage: 0.0477)\n",
      "Review: I found the film to be quite boring. The storyline was predictable and there was no character development. The acting was mediocre at best and the whole movie felt like a waste of time. Definitely not worth watching. -> Prediction: Pos (Percentage: 0.9921)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "new_reviews = [\n",
    "    \"It was a boring movie. I don't want to recommend it.\",\n",
    "    \"The movie was extremely disappoing.\"\n",
    "]\"\"\"\n",
    "\n",
    "new_reviews = [\n",
    "    \"I absolutely loved this movie. The storyline was gripping and the characters were very well developed. The performances were outstanding and the direction was top-notch. The cinematography was beautiful and the soundtrack was perfect. This is one of the best movies I've seen in a long time and I would highly recommend it to everyone.\",\n",
    "    \"This film was an incredible journey from start to finish. The visuals were stunning and the soundtrack perfectly complemented the emotional tone of the movie. The plot was engaging and the characters were relatable and well-acted. It left a lasting impression on me and I can’t wait to watch it again. A must-see for any movie lover!\",\n",
    "    \"The movie was extremely disappointing. The plot was weak and the characters were not believable. The acting was subpar and the film dragged on far too long. I wouldn't recommend this movie.\",\n",
    "    \"I found the film to be quite boring. The storyline was predictable and there was no character development. The acting was mediocre at best and the whole movie felt like a waste of time. Definitely not worth watching.\"\n",
    "]\n",
    "\n",
    "new_sequences = []\n",
    "for review in new_reviews:\n",
    "    sequence = [word_index.get(word.lower(), 2) for word in review.replace('.', ' ').split()]\n",
    "    sequence = [index if index < max_features else 2 for index in sequence]\n",
    "    new_sequences.append(sequence)\n",
    "\n",
    "\n",
    "padded_new_sequences = preprocessing.sequence.pad_sequences(new_sequences, maxlen=maxlen)\n",
    "\n",
    "predictions = model.predict(padded_new_sequences)\n",
    "\n",
    "for review, prediction in zip(new_reviews, predictions):\n",
    "    print(f\"Review: {review} -> Prediction: {'Pos' if prediction > 0.5 else 'Neg'} (Percentage: {prediction[0]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53dd92f6-b267-4cf1-a8fe-7289e4aa018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 424, 444, 11, 17, 1, 766, 13, 3130, 2, 1, 102, 68, 52, 70, 1388, 1, 351, 68, 1336, 2, 1, 455, 13, 2, 1, 624, 13, 304, 2, 1, 813, 13, 401, 11, 6, 28, 4, 1, 115, 99, 204, 107, 8, 3, 193, 55, 2, 10, 59, 542, 383, 9, 5, 313], [11, 19, 13, 32, 1045, 1308, 36, 377, 5, 1360, 1, 2054, 68, 1377, 2, 1, 813, 947, 2, 1, 918, 1160, 4, 1, 17, 1, 111, 13, 1725, 2, 1, 102, 68, 2, 2, 2, 9, 314, 3, 5860, 1381, 20, 69, 2, 10, 2, 855, 5, 103, 9, 171, 3, 2, 15, 98, 17, 2], [1, 17, 13, 573, 1329, 1, 111, 13, 812, 2, 1, 102, 68, 21, 864, 1, 113, 13, 2, 2, 1, 19, 3314, 20, 227, 96, 193, 10, 583, 383, 11, 17], [10, 255, 1, 19, 5, 27, 176, 354, 1, 766, 13, 724, 2, 47, 13, 54, 106, 940, 1, 113, 13, 1498, 30, 115, 2, 1, 223, 17, 418, 37, 3, 434, 4, 55, 404, 21, 287, 146]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(new_sequences)\n",
    "print(new_sequences[0].count(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
