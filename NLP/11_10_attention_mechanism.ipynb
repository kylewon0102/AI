{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a19f9c8-e9ce-41d1-9ce5-67667bdaabee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.0391 - loss: 3.7906 - val_accuracy: 0.2002 - val_loss: 2.6035\n",
      "Epoch 2/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.2554 - loss: 2.4249 - val_accuracy: 0.3752 - val_loss: 2.0076\n",
      "Epoch 3/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.4312 - loss: 1.9072 - val_accuracy: 0.5334 - val_loss: 1.6664\n",
      "Epoch 4/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.5586 - loss: 1.6051 - val_accuracy: 0.6339 - val_loss: 1.4353\n",
      "Epoch 5/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.6466 - loss: 1.3874 - val_accuracy: 0.6797 - val_loss: 1.2621\n",
      "Epoch 6/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.7111 - loss: 1.2192 - val_accuracy: 0.7619 - val_loss: 1.1188\n",
      "Epoch 7/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.7580 - loss: 1.0903 - val_accuracy: 0.8078 - val_loss: 0.9994\n",
      "Epoch 8/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.8002 - loss: 0.9778 - val_accuracy: 0.8061 - val_loss: 0.9104\n",
      "Epoch 9/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.8209 - loss: 0.8875 - val_accuracy: 0.8329 - val_loss: 0.8288\n",
      "Epoch 10/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.8487 - loss: 0.8087 - val_accuracy: 0.8523 - val_loss: 0.7618\n",
      "Epoch 11/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.8752 - loss: 0.7416 - val_accuracy: 0.8926 - val_loss: 0.6955\n",
      "Epoch 12/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.8907 - loss: 0.6841 - val_accuracy: 0.8934 - val_loss: 0.6527\n",
      "Epoch 13/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9043 - loss: 0.6344 - val_accuracy: 0.9197 - val_loss: 0.6016\n",
      "Epoch 14/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9166 - loss: 0.5901 - val_accuracy: 0.9183 - val_loss: 0.5620\n",
      "Epoch 15/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9244 - loss: 0.5499 - val_accuracy: 0.9291 - val_loss: 0.5343\n",
      "Epoch 16/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9366 - loss: 0.5168 - val_accuracy: 0.9436 - val_loss: 0.4915\n",
      "Epoch 17/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9447 - loss: 0.4834 - val_accuracy: 0.9523 - val_loss: 0.4635\n",
      "Epoch 18/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9526 - loss: 0.4539 - val_accuracy: 0.9554 - val_loss: 0.4426\n",
      "Epoch 19/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9553 - loss: 0.4284 - val_accuracy: 0.9535 - val_loss: 0.4144\n",
      "Epoch 20/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9544 - loss: 0.4172 - val_accuracy: 0.8792 - val_loss: 0.5115\n",
      "Epoch 21/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9252 - loss: 0.4514 - val_accuracy: 0.9561 - val_loss: 0.3966\n",
      "Epoch 22/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9614 - loss: 0.3868 - val_accuracy: 0.9585 - val_loss: 0.3736\n",
      "Epoch 23/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9680 - loss: 0.3611 - val_accuracy: 0.9732 - val_loss: 0.3456\n",
      "Epoch 24/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9735 - loss: 0.3422 - val_accuracy: 0.9697 - val_loss: 0.3364\n",
      "Epoch 25/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9760 - loss: 0.3238 - val_accuracy: 0.9725 - val_loss: 0.3197\n",
      "Epoch 26/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9754 - loss: 0.3101 - val_accuracy: 0.9700 - val_loss: 0.3048\n",
      "Epoch 27/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9782 - loss: 0.2945 - val_accuracy: 0.9841 - val_loss: 0.2802\n",
      "Epoch 28/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9805 - loss: 0.2804 - val_accuracy: 0.9781 - val_loss: 0.2757\n",
      "Epoch 29/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9824 - loss: 0.2647 - val_accuracy: 0.9922 - val_loss: 0.2498\n",
      "Epoch 30/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9841 - loss: 0.2532 - val_accuracy: 0.9608 - val_loss: 0.2847\n",
      "Epoch 31/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9834 - loss: 0.2430 - val_accuracy: 0.9915 - val_loss: 0.2291\n",
      "Epoch 32/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9826 - loss: 0.2300 - val_accuracy: 0.9872 - val_loss: 0.2201\n",
      "Epoch 33/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9862 - loss: 0.2164 - val_accuracy: 0.9932 - val_loss: 0.2058\n",
      "Epoch 34/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9859 - loss: 0.2089 - val_accuracy: 0.9885 - val_loss: 0.1962\n",
      "Epoch 35/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9829 - loss: 0.2049 - val_accuracy: 0.9960 - val_loss: 0.1847\n",
      "Epoch 36/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9881 - loss: 0.1885 - val_accuracy: 0.9950 - val_loss: 0.1764\n",
      "Epoch 37/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9911 - loss: 0.1763 - val_accuracy: 0.9959 - val_loss: 0.1676\n",
      "Epoch 38/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - accuracy: 0.9869 - loss: 0.1745 - val_accuracy: 0.9832 - val_loss: 0.1706\n",
      "Epoch 39/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - accuracy: 0.9880 - loss: 0.1654 - val_accuracy: 0.9834 - val_loss: 0.1617\n",
      "Epoch 40/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9893 - loss: 0.1561 - val_accuracy: 0.9938 - val_loss: 0.1461\n",
      "Epoch 41/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9946 - loss: 0.1414 - val_accuracy: 0.9748 - val_loss: 0.1724\n",
      "Epoch 42/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9838 - loss: 0.1549 - val_accuracy: 0.9629 - val_loss: 0.1762\n",
      "Epoch 43/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9866 - loss: 0.1413 - val_accuracy: 0.9976 - val_loss: 0.1230\n",
      "Epoch 44/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.9895 - loss: 0.1314 - val_accuracy: 0.9978 - val_loss: 0.1140\n",
      "Epoch 45/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - accuracy: 0.9920 - loss: 0.1223 - val_accuracy: 0.9954 - val_loss: 0.1155\n",
      "Epoch 46/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9881 - loss: 0.1215 - val_accuracy: 0.9881 - val_loss: 0.1215\n",
      "Epoch 47/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 30ms/step - accuracy: 0.9941 - loss: 0.1081 - val_accuracy: 0.9814 - val_loss: 0.1271\n",
      "Epoch 48/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9919 - loss: 0.1063 - val_accuracy: 0.9884 - val_loss: 0.1052\n",
      "Epoch 49/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.9946 - loss: 0.0965 - val_accuracy: 0.9988 - val_loss: 0.0883\n",
      "Epoch 50/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9931 - loss: 0.0966 - val_accuracy: 0.9944 - val_loss: 0.0927\n",
      "Epoch 51/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9894 - loss: 0.0965 - val_accuracy: 0.9987 - val_loss: 0.0792\n",
      "Epoch 52/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9926 - loss: 0.0879 - val_accuracy: 0.9986 - val_loss: 0.0743\n",
      "Epoch 53/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9931 - loss: 0.0854 - val_accuracy: 0.9716 - val_loss: 0.1225\n",
      "Epoch 54/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9852 - loss: 0.1006 - val_accuracy: 0.9981 - val_loss: 0.0687\n",
      "Epoch 55/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9930 - loss: 0.0761 - val_accuracy: 0.9989 - val_loss: 0.0653\n",
      "Epoch 56/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 30ms/step - accuracy: 0.9903 - loss: 0.0803 - val_accuracy: 0.9990 - val_loss: 0.0611\n",
      "Epoch 57/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 31ms/step - accuracy: 0.9937 - loss: 0.0695 - val_accuracy: 0.9986 - val_loss: 0.0620\n",
      "Epoch 58/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9885 - loss: 0.0781 - val_accuracy: 0.9817 - val_loss: 0.0891\n",
      "Epoch 59/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9927 - loss: 0.0658 - val_accuracy: 0.9989 - val_loss: 0.0525\n",
      "Epoch 60/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9892 - loss: 0.0756 - val_accuracy: 0.9756 - val_loss: 0.0916\n",
      "Epoch 61/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9924 - loss: 0.0614 - val_accuracy: 0.9544 - val_loss: 0.1892\n",
      "Epoch 62/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9880 - loss: 0.0742 - val_accuracy: 0.9990 - val_loss: 0.0455\n",
      "Epoch 63/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.9920 - loss: 0.0598 - val_accuracy: 0.9991 - val_loss: 0.0448\n",
      "Epoch 64/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - accuracy: 0.9976 - loss: 0.0460 - val_accuracy: 0.9991 - val_loss: 0.0425\n",
      "Epoch 65/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.9917 - loss: 0.0561 - val_accuracy: 0.9976 - val_loss: 0.0470\n",
      "Epoch 66/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9966 - loss: 0.0448 - val_accuracy: 0.9991 - val_loss: 0.0375\n",
      "Epoch 67/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9868 - loss: 0.0701 - val_accuracy: 0.9886 - val_loss: 0.0586\n",
      "Epoch 68/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9866 - loss: 0.0629 - val_accuracy: 0.9916 - val_loss: 0.0471\n",
      "Epoch 69/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9964 - loss: 0.0393 - val_accuracy: 0.9991 - val_loss: 0.0369\n",
      "Epoch 70/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9947 - loss: 0.0431 - val_accuracy: 0.9991 - val_loss: 0.0307\n",
      "Epoch 71/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9930 - loss: 0.0480 - val_accuracy: 0.9669 - val_loss: 0.0969\n",
      "Epoch 72/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9940 - loss: 0.0420 - val_accuracy: 0.9910 - val_loss: 0.0500\n",
      "Epoch 73/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9915 - loss: 0.0460 - val_accuracy: 0.9938 - val_loss: 0.0411\n",
      "Epoch 74/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9922 - loss: 0.0423 - val_accuracy: 0.9892 - val_loss: 0.0451\n",
      "Epoch 75/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9906 - loss: 0.0528 - val_accuracy: 0.9985 - val_loss: 0.0269\n",
      "Epoch 76/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9917 - loss: 0.0491 - val_accuracy: 0.9993 - val_loss: 0.0234\n",
      "Epoch 77/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9953 - loss: 0.0325 - val_accuracy: 0.9992 - val_loss: 0.0232\n",
      "Epoch 78/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9975 - loss: 0.0264 - val_accuracy: 0.9993 - val_loss: 0.0219\n",
      "Epoch 79/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9966 - loss: 0.0279 - val_accuracy: 0.9992 - val_loss: 0.0203\n",
      "Epoch 80/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9933 - loss: 0.0399 - val_accuracy: 0.9985 - val_loss: 0.0244\n",
      "Epoch 81/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9946 - loss: 0.0318 - val_accuracy: 0.9885 - val_loss: 0.0415\n",
      "Epoch 82/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9963 - loss: 0.0266 - val_accuracy: 0.9559 - val_loss: 0.1152\n",
      "Epoch 83/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9950 - loss: 0.0290 - val_accuracy: 0.9966 - val_loss: 0.0261\n",
      "Epoch 84/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9954 - loss: 0.0291 - val_accuracy: 0.9993 - val_loss: 0.0173\n",
      "Epoch 85/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9949 - loss: 0.0292 - val_accuracy: 0.9627 - val_loss: 0.1329\n",
      "Epoch 86/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9914 - loss: 0.0385 - val_accuracy: 0.9993 - val_loss: 0.0158\n",
      "Epoch 87/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9978 - loss: 0.0194 - val_accuracy: 0.9993 - val_loss: 0.0162\n",
      "Epoch 88/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9969 - loss: 0.0223 - val_accuracy: 0.9993 - val_loss: 0.0145\n",
      "Epoch 89/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9963 - loss: 0.0230 - val_accuracy: 0.9890 - val_loss: 0.0335\n",
      "Epoch 90/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9822 - loss: 0.0718 - val_accuracy: 0.9772 - val_loss: 0.0594\n",
      "Epoch 91/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.0263 - val_accuracy: 0.9993 - val_loss: 0.0136\n",
      "Epoch 92/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0152 - val_accuracy: 0.9485 - val_loss: 0.2500\n",
      "Epoch 93/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9886 - loss: 0.0466 - val_accuracy: 0.9994 - val_loss: 0.0123\n",
      "Epoch 94/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9981 - loss: 0.0158 - val_accuracy: 0.9900 - val_loss: 0.0297\n",
      "Epoch 95/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9897 - loss: 0.0357 - val_accuracy: 0.9995 - val_loss: 0.0114\n",
      "Epoch 96/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9986 - loss: 0.0131 - val_accuracy: 0.9903 - val_loss: 0.0355\n",
      "Epoch 97/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9974 - loss: 0.0168 - val_accuracy: 0.9903 - val_loss: 0.0289\n",
      "Epoch 98/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9912 - loss: 0.0320 - val_accuracy: 0.9994 - val_loss: 0.0106\n",
      "Epoch 99/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.0227 - val_accuracy: 0.9994 - val_loss: 0.0101\n",
      "Epoch 100/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9932 - loss: 0.0265 - val_accuracy: 0.9994 - val_loss: 0.0100\n",
      "Epoch 101/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.9992 - loss: 0.0099 - val_accuracy: 0.9977 - val_loss: 0.0143\n",
      "Epoch 102/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9921 - loss: 0.0295 - val_accuracy: 0.9588 - val_loss: 0.1622\n",
      "Epoch 103/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9909 - loss: 0.0357 - val_accuracy: 0.9994 - val_loss: 0.0093\n",
      "Epoch 104/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0137 - val_accuracy: 0.9993 - val_loss: 0.0095\n",
      "Epoch 105/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.9993 - loss: 0.0086 - val_accuracy: 0.9995 - val_loss: 0.0080\n",
      "Epoch 106/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0109 - val_accuracy: 0.9681 - val_loss: 0.0994\n",
      "Epoch 107/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.9910 - loss: 0.0368 - val_accuracy: 0.9990 - val_loss: 0.0172\n",
      "Epoch 108/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9953 - loss: 0.0230 - val_accuracy: 0.9973 - val_loss: 0.0200\n",
      "Epoch 109/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.9981 - loss: 0.0157 - val_accuracy: 0.9994 - val_loss: 0.0121\n",
      "Epoch 110/500\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 30ms/step - accuracy: 0.9972 - loss: 0.0175 - val_accuracy: 0.9992 - val_loss: 0.0127\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dot, LSTM, Dense, Concatenate, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "cal_len = 5 #10으로 하면 (Seq2Seq 방식) 정확도가 떨어짐 LSTM 이라\n",
    "chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "num_classes = len(chars)\n",
    "\n",
    "char_to_index = {char: idx for idx, char in enumerate(chars)}\n",
    "index_to_char = {idx: char for idx, char in enumerate(chars)}\n",
    "\n",
    "def generate_data(num_samples):\n",
    "    x = []\n",
    "    y = []\n",
    "    for _ in range(num_samples):\n",
    "        sequence = np.random.choice(list(chars), 15)\n",
    "        x.append([char_to_index[char] for char in sequence])\n",
    "        y.append([char_to_index[char] for char in sequence[::-1]])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "num_samples = 20000\n",
    "x, y = generate_data(num_samples)\n",
    "\n",
    "        \n",
    "x = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "y = y.reshape(y.shape[0], y.shape[1], 1)\n",
    "\n",
    "#encoder\n",
    "encoder_inputs = Input(shape=(15, 1))\n",
    "encoder = LSTM(128, return_sequences = True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "#decoder\n",
    "decoder_inputs = Input(shape=(15, 1))\n",
    "decoder = LSTM(128, return_state=True, return_sequences = True)\n",
    "decoder_outputs, _, _ = decoder(decoder_inputs, initial_state = encoder_states)\n",
    "\n",
    "#attention mechanism\n",
    "attention = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs])\n",
    "attention = Activation('softmax')(attention)\n",
    "context = Dot(axes=[2, 1])([attention, encoder_outputs])\n",
    "\n",
    "decoder_combined_context = Concatenate(axis=-1)([decoder_outputs, context])\n",
    "\n",
    "decoder_dense = Dense(num_classes, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "decoder_input_data = np.zeros_like(x)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience = 5, restore_best_weights = True)\n",
    "\n",
    "history= model.fit([x, decoder_input_data], y, epochs=500, batch_size=32, validation_split=(0.2), callbacks=[early_stop])\n",
    "\n",
    "def predict_reverse(input_sequence):\n",
    "    input_sequence = np.array([char_to_index[char] for char in input_sequence]).reshape((1, 15, 1))\n",
    "    decoder_input = np.zeros((1, 15, 1))\n",
    "    predicted_sequence = model.predict([input_sequence, decoder_input])\n",
    "    predicted_indices = np.argmax(predicted_sequence, axis=-1).reshape((15, ))\n",
    "    return ''.join([index_to_char[idx] for idx in predicted_indices])\n",
    "\n",
    "test_strings = [\"\".join(np.random.choice(list(chars), 15)) for _ in range(30)]\n",
    "\n",
    "expected_outputs = [s[::-1] for s in test_strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5e03fd7-b1dc-47bb-b675-11d2eee82d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
      "input : NtGWuiHtGWxqDIP\n",
      "est. output: PIDqxWGtHiuWGtN\n",
      "exp. output: PIDqxWGtHiuWGtN\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "input : oPqRYzcqWXHJcRO\n",
      "est. output: ORcJHXWqczYRqPo\n",
      "exp. output: ORcJHXWqczYRqPo\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "input : dRTmtqFotGDMPNh\n",
      "est. output: hNPMDGtoFqtmTRd\n",
      "exp. output: hNPMDGtoFqtmTRd\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "input : APAcOBksHtNyVDi\n",
      "est. output: iDVyNtHskBOcAPA\n",
      "exp. output: iDVyNtHskBOcAPA\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "input : IeWsunPIEysPoAz\n",
      "est. output: zAoPsyEIPnusWeI\n",
      "exp. output: zAoPsyEIPnusWeI\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "input : YCuXVKgFDquHyvr\n",
      "est. output: rvyHuqDFgKVXuCY\n",
      "exp. output: rvyHuqDFgKVXuCY\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "input : ajmPoBVTjXDUINA\n",
      "est. output: ANIUDXjTVBoPmja\n",
      "exp. output: ANIUDXjTVBoPmja\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "input : TjpsBHHNejfQijQ\n",
      "est. output: QjiQfjeNHHBspjT\n",
      "exp. output: QjiQfjeNHHBspjT\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "input : cLbYrSVcBviWMDF\n",
      "est. output: FDMWivBcVSrYbLc\n",
      "exp. output: FDMWivBcVSrYbLc\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "input : zqTsBcuirCmHFlk\n",
      "est. output: klFHmCriucBsTqz\n",
      "exp. output: klFHmCriucBsTqz\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "input : tkdEJCsBIMGnGRu\n",
      "est. output: uRGnGMIBsCJEdkt\n",
      "exp. output: uRGnGMIBsCJEdkt\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "input : PmVCxbMeFuQrbzP\n",
      "est. output: PzbrQuFeMbxCVmP\n",
      "exp. output: PzbrQuFeMbxCVmP\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "input : NYTZYCeKAQAbwnN\n",
      "est. output: NnwbAQAKeCYZTYN\n",
      "exp. output: NnwbAQAKeCYZTYN\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "input : ossPQCgUUkmPEfl\n",
      "est. output: lfEPmkUUgCQPsso\n",
      "exp. output: lfEPmkUUgCQPsso\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "input : NXNNuRRFtXqXjYP\n",
      "est. output: PYjXqXtFRRuNNXN\n",
      "exp. output: PYjXqXtFRRuNNXN\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "input : vJNkhTarHkwxbwz\n",
      "est. output: zwbxwkHraThkNJv\n",
      "exp. output: zwbxwkHraThkNJv\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "input : PjVwDzQnhAnXeiq\n",
      "est. output: qieXnAhnQzDwVjP\n",
      "exp. output: qieXnAhnQzDwVjP\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "input : czSOEBYZgWlatxr\n",
      "est. output: rxtalWgZYBEOSzc\n",
      "exp. output: rxtalWgZYBEOSzc\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "input : dlXbcZgrqesmtVq\n",
      "est. output: qVtmseqrgZcbXld\n",
      "exp. output: qVtmseqrgZcbXld\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "input : mrDCSXfzRTlISXf\n",
      "est. output: fXSIlTRzfXSCDrm\n",
      "exp. output: fXSIlTRzfXSCDrm\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "input : vUvESRgCVHhJAsW\n",
      "est. output: WsAJhHVCgRSEvUv\n",
      "exp. output: WsAJhHVCgRSEvUv\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "input : SjkTvkxJwKVDqim\n",
      "est. output: miqDVKwJxkvTkjS\n",
      "exp. output: miqDVKwJxkvTkjS\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "input : NWVcplLWBxEVkgf\n",
      "est. output: fgkVExBWLlpcVWN\n",
      "exp. output: fgkVExBWLlpcVWN\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "input : oWAwRVnMUtCfEsN\n",
      "est. output: NsEfCtUMnVRwAWo\n",
      "exp. output: NsEfCtUMnVRwAWo\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "input : vjKJViJTHGroPjX\n",
      "est. output: XjPorGHTJiVJKjv\n",
      "exp. output: XjPorGHTJiVJKjv\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "input : PrGLlKmpMunsWJt\n",
      "est. output: tJWsnuMpmKlLGrP\n",
      "exp. output: tJWsnuMpmKlLGrP\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "input : QTOHlZmSvIaLXIs\n",
      "est. output: sIXLaIvSmZlHOTQ\n",
      "exp. output: sIXLaIvSmZlHOTQ\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "input : qvgIDmrrkTtitnN\n",
      "est. output: NntitTkrrmDIgvq\n",
      "exp. output: NntitTkrrmDIgvq\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "input : sEmEFdlrhXaVADq\n",
      "est. output: qDAVaXhrldFEmEs\n",
      "exp. output: qDAVaXhrldFEmEs\n",
      "correct: 맞음\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "input : mLTcksCLUElezHw\n",
      "est. output: wHzelEULCskcTLm\n",
      "exp. output: wHzelEULCskcTLm\n",
      "correct: 맞음\n",
      "total acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "total_predictions = len(test_strings)\n",
    "\n",
    "for i, test_string in enumerate(test_strings):\n",
    "    predicted_output = predict_reverse(test_string)\n",
    "    is_correct = predicted_output == expected_outputs[i]\n",
    "    if is_correct:\n",
    "        correct_predictions += 1\n",
    "    print(f\"input : {test_string}\")\n",
    "    print(f\"est. output: {predicted_output}\")\n",
    "    print(f\"exp. output: {expected_outputs[i]}\")\n",
    "    print(f\"correct: {'맞음' if is_correct else '틀림'}\")\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"total acc: {accuracy *100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
