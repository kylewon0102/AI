{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ce9e6c-7a12-4d27-a420-bc50936ba57d",
   "metadata": {},
   "source": [
    "Basic Perceptron\n",
    "- \n",
    "\n",
    "First Neural Network (basic one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "335810c0-f147-4385-be56-96905a9aada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 cost =  1.2608904 W =  [[0.83152276]\n",
      " [1.7845541 ]] b =  [0.91905296]\n",
      "step =  200 cost =  0.9144542 W =  [[0.47666812]\n",
      " [1.3684222 ]] b =  [0.29653335]\n",
      "step =  400 cost =  0.7681107 W =  [[0.25439087]\n",
      " [1.0589746 ]] b =  [-0.07854505]\n",
      "step =  600 cost =  0.72330856 W =  [[0.14194913]\n",
      " [0.85633826]] b =  [-0.25987196]\n",
      "step =  800 cost =  0.7104429 W =  [[0.09276118]\n",
      " [0.724376  ]] b =  [-0.3310317]\n",
      "step =  1000 cost =  0.7057456 W =  [[0.07404535]\n",
      " [0.6319607 ]] b =  [-0.34859926]\n",
      "step =  1200 cost =  0.70319754 W =  [[0.06870159]\n",
      " [0.5613962 ]] b =  [-0.34200093]\n",
      "step =  1400 cost =  0.701388 W =  [[0.06865838]\n",
      " [0.503701  ]] b =  [-0.32528415]\n",
      "step =  1600 cost =  0.69996154 W =  [[0.0702849 ]\n",
      " [0.45438096]] b =  [-0.3049327]\n",
      "step =  1800 cost =  0.6988012 W =  [[0.07202883]\n",
      " [0.41111344]] b =  [-0.28386635]\n",
      "step =  2000 cost =  0.69784826 W =  [[0.07328687]\n",
      " [0.3726113 ]] b =  [-0.26335627]\n",
      "step =  2200 cost =  0.69706285 W =  [[0.07387783]\n",
      " [0.33808756]] b =  [-0.24391787]\n",
      "step =  2400 cost =  0.6964138 W =  [[0.07380094]\n",
      " [0.3070034 ]] b =  [-0.22572601]\n",
      "step =  2600 cost =  0.6958767 W =  [[0.07312603]\n",
      " [0.27895182]] b =  [-0.20880339]\n",
      "step =  2800 cost =  0.6954313 W =  [[0.07194497]\n",
      " [0.25360167]] b =  [-0.1931077]\n",
      "step =  3000 cost =  0.69506127 W =  [[0.07035043]\n",
      " [0.23067217]] b =  [-0.17857179]\n",
      "step =  3200 cost =  0.6947534 W =  [[0.06842795]\n",
      " [0.20991749]] b =  [-0.1651196]\n",
      "step =  3400 cost =  0.6944968 W =  [[0.06625292]\n",
      " [0.19112036]] b =  [-0.1526751]\n",
      "step =  3600 cost =  0.69428265 W =  [[0.06389033]\n",
      " [0.17408694]] b =  [-0.14116515]\n",
      "step =  3800 cost =  0.69410354 W =  [[0.06139538]\n",
      " [0.15864383]] b =  [-0.13052061]\n",
      "step =  4000 cost =  0.6939535 W =  [[0.05881457]\n",
      " [0.14463557]] b =  [-0.12067721]\n",
      "step =  4200 cost =  0.6938278 W =  [[0.05618665]\n",
      " [0.13192265]] b =  [-0.111575]\n",
      "step =  4400 cost =  0.6937221 W =  [[0.05354363]\n",
      " [0.12037931]] b =  [-0.1031585]\n",
      "step =  4600 cost =  0.69363344 W =  [[0.05091188]\n",
      " [0.10989293]] b =  [-0.09537625]\n",
      "step =  4800 cost =  0.69355875 W =  [[0.04831275]\n",
      " [0.10036213]] b =  [-0.08818051]\n",
      "step =  5000 cost =  0.6934958 W =  [[0.04576334]\n",
      " [0.09169549]] b =  [-0.08152729]\n",
      "step =  5200 cost =  0.6934427 W =  [[0.04327715]\n",
      " [0.08381097]] b =  [-0.07537567]\n",
      "step =  5400 cost =  0.6933979 W =  [[0.04086468]\n",
      " [0.0766345 ]] b =  [-0.069688]\n",
      "step =  5600 cost =  0.6933599 W =  [[0.03853375]\n",
      " [0.0700995 ]] b =  [-0.06442925]\n",
      "step =  5800 cost =  0.6933278 W =  [[0.03629011]\n",
      " [0.06414581]] b =  [-0.05956716]\n",
      "step =  6000 cost =  0.6933007 W =  [[0.03413755]\n",
      " [0.05871926]] b =  [-0.05507186]\n",
      "step =  6200 cost =  0.69327766 W =  [[0.03207844]\n",
      " [0.05377094]] b =  [-0.0509157]\n",
      "step =  6400 cost =  0.69325817 W =  [[0.03011386]\n",
      " [0.04925674]] b =  [-0.04707309]\n",
      "step =  6600 cost =  0.6932415 W =  [[0.02824385]\n",
      " [0.04513677]] b =  [-0.04352044]\n",
      "step =  6800 cost =  0.6932275 W =  [[0.02646757]\n",
      " [0.04137497]] b =  [-0.04023586]\n",
      "step =  7000 cost =  0.6932156 W =  [[0.02478356]\n",
      " [0.03793879]] b =  [-0.03719914]\n",
      "step =  7200 cost =  0.6932054 W =  [[0.02318974]\n",
      " [0.03479877]] b =  [-0.03439155]\n",
      "step =  7400 cost =  0.69319683 W =  [[0.02168367]\n",
      " [0.03192822]] b =  [-0.03179585]\n",
      "step =  7600 cost =  0.6931895 W =  [[0.02026256]\n",
      " [0.029303  ]] b =  [-0.02939603]\n",
      "step =  7800 cost =  0.6931833 W =  [[0.01892336]\n",
      " [0.02690122]] b =  [-0.02717734]\n",
      "step =  8000 cost =  0.69317794 W =  [[0.01766286]\n",
      " [0.02470304]] b =  [-0.0251261]\n",
      "step =  8200 cost =  0.6931734 W =  [[0.01647781]\n",
      " [0.02269048]] b =  [-0.02322965]\n",
      "step =  8400 cost =  0.6931695 W =  [[0.01536477]\n",
      " [0.02084721]] b =  [-0.02147634]\n",
      "step =  8600 cost =  0.69316626 W =  [[0.01432038]\n",
      " [0.01915839]] b =  [-0.01985536]\n",
      "step =  8800 cost =  0.6931634 W =  [[0.01334125]\n",
      " [0.01761062]] b =  [-0.0183567]\n",
      "step =  9000 cost =  0.6931611 W =  [[0.01242407]\n",
      " [0.01619161]] b =  [-0.01697117]\n",
      "step =  9200 cost =  0.6931591 W =  [[0.01156555]\n",
      " [0.01489026]] b =  [-0.01569022]\n",
      "step =  9400 cost =  0.6931573 W =  [[0.01076252]\n",
      " [0.01369644]] b =  [-0.01450595]\n",
      "step =  9600 cost =  0.6931558 W =  [[0.01001188]\n",
      " [0.01260095]] b =  [-0.01341106]\n",
      "step =  9800 cost =  0.6931546 W =  [[0.00931065]\n",
      " [0.01159539]] b =  [-0.01239881]\n",
      "step =  10000 cost =  0.6931535 W =  [[0.00865594]\n",
      " [0.01067213]] b =  [-0.01146296]\n",
      "\n",
      "Accuracy:  0.25\n",
      "new data hyp:  [[0.5019663 ]\n",
      " [0.4998023 ]\n",
      " [0.49929824]\n",
      " [0.4971343 ]]  new data predict:  [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "#y_data = np.array([[0], [0], [0], [1]], dtype=np.float32) #and\n",
    "#y_data = np.array([[0], [1], [1], [1]], dtype=np.float32) #or\n",
    "#y_data = np.array([[1], [1], [1], [0]], dtype=np.float32) #nand\n",
    "#y_data = np.array([[1], [0], [0], [0]], dtype=np.float32) #nor\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32) #xor\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 2], name='x-input') #x 두개 짜리 데이터 그릇\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1], name='y-input') #y 한개 짜리 데이터 그릇\n",
    "\n",
    "w = tf.Variable(tf.random_normal([2, 1], name = 'weight'))\n",
    "b = tf.Variable(tf.random_normal([1], name = 'bias'))\n",
    "\n",
    "#y 시그모이드 함수 방정식 사용\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, w)+ b)\n",
    "\n",
    "#오차 함수\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1 - Y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "#정확도\n",
    "predicted = tf.cast(hypothesis>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10001):  \n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if i % 200 == 0:\n",
    "            print(\"step = \", i,\n",
    "                  \"cost = \", sess.run(cost, feed_dict={X:x_data, Y:y_data}),\n",
    "                  \"W = \", sess.run(w), \"b = \", sess.run(b))\n",
    "    \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "    \n",
    "    print(\"\\nAccuracy: \", a)\n",
    "\n",
    "    new_data = np.array([[1, 1], [0, 1], [1, 0], [0, 0]], dtype=np.float32)\n",
    "    new_prediction = sess.run(predicted, feed_dict={X:new_data})\n",
    "    new_hypothesis = sess.run(hypothesis, feed_dict={X:new_data})\n",
    "    print(\"new data hyp: \", new_hypothesis, \" new data predict: \", new_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e94cac-bffd-4a05-b796-71e24721b23d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
