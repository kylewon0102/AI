{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f5f710-020e-44ac-b205-bd1682b0e55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 값: (0, 0)출력 값: 0\n",
      "입력 값: (1, 0)출력 값: 1\n",
      "입력 값: (0, 1)출력 값: 1\n",
      "입력 값: (1, 1)출력 값: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w11 = np.array([-2, -2])\n",
    "w12 = np.array([2, 2])\n",
    "w2 = np.array([1, 1])\n",
    "b1 = 3\n",
    "b2 = -1\n",
    "b3 = -1\n",
    "\n",
    "def MLP(x, w, b):\n",
    "    y = np.sum(w * x) + b\n",
    "    if y <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def NAND(x1, x2):\n",
    "    return MLP(np.array([x1, x2]), w11, b1)\n",
    "\n",
    "def OR(x1, x2):\n",
    "    return MLP(np.array([x1, x2]), w12, b2)\n",
    "\n",
    "def AND(x1, x2):\n",
    "    return MLP(np.array([x1, x2]), w2, b3)\n",
    "\n",
    "def XOR(x1, x2):\n",
    "    return AND(NAND(x1, x2), OR(x1, x2))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for x in [(0, 0), (1, 0), (0, 1), (1, 1)]:\n",
    "        y = XOR(x[0], x[1])\n",
    "        print(\"입력 값: \" + str(x) + \"출력 값: \" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "030191fb-58b8-4618-9baa-d6f40bcb1fa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 21:03:40.043118: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 500, cost = 0.703790307, w = [0.51884794 0.06409978], b = -0.16101372241973877\n",
      "step = 1000, cost = 0.697289169, w = [0.3622901  0.02921341], b = -0.2066900134086609\n",
      "step = 1500, cost = 0.695655227, w = [0.2767561  0.03295634], b = -0.18026258051395416\n",
      "step = 2000, cost = 0.694711685, w = [0.21569085 0.03728088], b = -0.14960385859012604\n",
      "step = 2500, cost = 0.694134712, w = [0.16913933 0.03859998], b = -0.12316592037677765\n",
      "step = 3000, cost = 0.693777144, w = [0.13311978 0.03761426], b = -0.10126187652349472\n",
      "step = 3500, cost = 0.693552732, w = [0.10510145 0.03523072], b = -0.08323230594396591\n",
      "step = 4000, cost = 0.693410456, w = [0.08322831 0.03211305], b = -0.06840873509645462\n",
      "step = 4500, cost = 0.693319261, w = [0.06609616 0.02870237], b = -0.05622385814785957\n",
      "step = 5000, cost = 0.693260431, w = [0.05263427 0.02527872], b = -0.04620874300599098\n",
      "step = 5500, cost = 0.693221986, w = [0.04202313 0.02201118], b = -0.037977274507284164\n",
      "step = 6000, cost = 0.693196774, w = [0.03363349 0.01899383], b = -0.031211934983730316\n",
      "step = 6500, cost = 0.693180203, w = [0.02698086 0.01627127], b = -0.025651682168245316\n",
      "step = 7000, cost = 0.693169236, w = [0.02169074 0.01385619], b = -0.021081894636154175\n",
      "step = 7500, cost = 0.693161964, w = [0.01747282 0.01174149], b = -0.017326166853308678\n",
      "step = 8000, cost = 0.693157077, w = [0.01410126 0.00990852], b = -0.014239512383937836\n",
      "step = 8500, cost = 0.693153858, w = [0.01139981 0.00833261], b = -0.011702723801136017\n",
      "step = 9000, cost = 0.693151653, w = [0.00923043 0.00698663], b = -0.00961785577237606\n",
      "step = 9500, cost = 0.693150163, w = [0.00748471 0.00584326], b = -0.00790440570563078\n",
      "step = 10000, cost = 0.693149209, w = [0.0060772  0.00487637], b = -0.006496216636151075\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = np.array([[0,0],[0, 1],[1, 0],[1, 1]], dtype = np.float32)\n",
    "y = np.array([[0], [1],[1], [0]], dtype = np.float32)\n",
    "\n",
    "w = tf.Variable(tf.random.uniform([2, 1], dtype = np.float32))\n",
    "b = tf.Variable(tf.random.uniform([1], dtype = np.float32))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+tf.exp(-x))\n",
    "\n",
    "def perceptron(x):\n",
    "    return sigmoid(tf.matmul(x, w) + b)\n",
    "\n",
    "def cost(y_true, y_pred):\n",
    "    return tf.reduce_mean(-(y_true * tf.math.log(y_pred) + (1 - y_true)*tf.math.log(1 -y_pred)))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01)\n",
    "\n",
    "def binary_output(x):\n",
    "    return int(x.numpy()[0][0] > 0.5)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct_prediction = tf.equal(tf.cast(y_pred > 0.5, tf.float32), y_true)\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "for epoch in range(10000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = perceptron(x)\n",
    "        loss = cost(y, pred)\n",
    "    gradients = tape.gradient(loss, [w,b])\n",
    "    optimizer.apply_gradients(zip(gradients, [w,b]))\n",
    "\n",
    "    if (epoch+1) %500 == 0:\n",
    "        w_val = np.squeeze(w.numpy())\n",
    "        b_val = np.squeeze(b.numpy())\n",
    "        print(f\"step = {epoch+1}, cost = {loss.numpy():.9f}, w = {w_val}, b = {b_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f17ba1f9-4526-4cf7-9798-326663cd2b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] [[0.49837536]\n",
      " [0.49959484]\n",
      " [0.49989524]\n",
      " [0.5011148 ]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(y, pred).numpy())\n",
    "print(y, pred.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96e66c76-eddd-430c-b76d-447053ef72f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로그저장 -> logs/mylogs/20250401-191807\n",
      "step = 500, cost = 0.692169607\n",
      "w = [[ 1.460471    2.3294432 ]\n",
      " [ 0.29151487 -0.92550796]], b = [-0.61677635  0.41012502]\n",
      "w = [[-0.09294717 -0.24510357]\n",
      " [-0.26391256 -0.5222988 ]], b = [-0.7541374  1.9055139]\n",
      "w = [0.14027849 0.7176617 ], b = -0.6116148233413696\n",
      "step = 1000, cost = 0.677582502\n",
      "w = [[ 1.3921965   2.721988  ]\n",
      " [ 0.28406507 -1.4733618 ]], b = [-0.6515003   0.94452786]\n",
      "w = [[-0.0346031  -0.30505243]\n",
      " [-0.563315   -1.5373144 ]], b = [-0.7130109  1.4254006]\n",
      "w = [0.4865203 1.3437825], b = -0.8244594931602478\n",
      "step = 1500, cost = 0.499317288\n",
      "w = [[ 1.5147808   4.6680593 ]\n",
      " [ 0.10711767 -4.097787  ]], b = [-0.638078   2.4892495]\n",
      "w = [[ 0.62897825  0.40783736]\n",
      " [-1.1553577  -5.0911717 ]], b = [-0.46142778  1.6489611 ]\n",
      "w = [1.2648015 4.825669 ], b = -1.1267364025115967\n",
      "step = 2000, cost = 0.038559850\n",
      "w = [[ 3.5729463  5.621095 ]\n",
      " [-3.7078707 -5.129745 ]], b = [-1.8700545  3.1098568]\n",
      "w = [[ 3.5009565  4.644341 ]\n",
      " [-1.8163918 -5.5630426]], b = [-0.39995536  2.68934   ]\n",
      "w = [3.3299575 7.537603 ], b = -4.405466556549072\n",
      "step = 2500, cost = 0.011745737\n",
      "w = [[ 4.086822   5.805106 ]\n",
      " [-4.2789373 -5.5206366]], b = [-2.1974516  3.057035 ]\n",
      "w = [[ 3.945778   5.5271964]\n",
      " [-2.3067458 -6.118828 ]], b = [-0.07377904  2.7955623 ]\n",
      "w = [3.9908059 8.969134 ], b = -5.391268730163574\n",
      "step = 3000, cost = 0.006725039\n",
      "w = [[ 4.2820563  5.8971505]\n",
      " [-4.489707  -5.668114 ]], b = [-2.31817    3.0576506]\n",
      "w = [[ 4.1283956  5.86335  ]\n",
      " [-2.5733485 -6.35891  ]], b = [0.1178456 2.8620286]\n",
      "w = [4.3198967 9.629581 ], b = -5.87648344039917\n",
      "step = 3500, cost = 0.004656520\n",
      "w = [[ 4.3989625  5.9581532]\n",
      " [-4.614321  -5.7550673]], b = [-2.3882632  3.0641806]\n",
      "w = [[ 4.243326   6.0651503]\n",
      " [-2.7559807 -6.5070577]], b = [0.25078648 2.9077418 ]\n",
      "w = [ 4.5437584 10.05379  ], b = -6.203147888183594\n",
      "step = 4000, cost = 0.003539924\n",
      "w = [[ 4.481117   6.003487 ]\n",
      " [-4.7011237 -5.8153987]], b = [-2.4363065  3.071524 ]\n",
      "w = [[ 4.3272367  6.2071724]\n",
      " [-2.894331  -6.612325 ]], b = [0.35138732 2.942103  ]\n",
      "w = [ 4.714529 10.364126], b = -6.449650287628174\n",
      "step = 4500, cost = 0.002845197\n",
      "w = [[ 4.5438766  6.0393977]\n",
      " [-4.766994  -5.8610215]], b = [-2.4722745  3.0786185]\n",
      "w = [[ 4.3933716  6.315765 ]\n",
      " [-3.0053177 -6.693135 ]], b = [0.43169272 2.9694357 ]\n",
      "w = [ 4.85301  10.607833], b = -6.64751672744751\n",
      "step = 5000, cost = 0.002373057\n",
      "w = [[ 4.5943546  6.0690355]\n",
      " [-4.8196945 -5.897411 ]], b = [-2.5007286  3.0852315]\n",
      "w = [[ 4.447988   6.403162 ]\n",
      " [-3.097741  -6.7582774]], b = [0.49816737 2.9920301 ]\n",
      "w = [ 4.969688 10.807973], b = -6.812698841094971\n",
      "입력: [0.0, 0.0], 예측(확률): 0.0031, 예측(이진): 0\n",
      "입력: [0.0, 1.0], 예측(확률): 0.9979, 예측(이진): 1\n",
      "입력: [1.0, 0.0], 예측(확률): 0.9986, 예측(이진): 1\n",
      "입력: [1.0, 1.0], 예측(확률): 0.0028, 예측(이진): 0\n",
      "정확도: 1.0000\n",
      "TensorBoard 로그 저장 경로: logs/mylogs/20250401-191807\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "x = np.array([[0,0],[0, 1],[1, 0],[1, 1]], dtype = np.float32)\n",
    "y = np.array([[0], [1], [1], [0]], dtype = np.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random.normal([2, 2]))\n",
    "b1 = tf.Variable(tf.random.normal([2]))\n",
    "\n",
    "w2 = tf.Variable(tf.random.normal([2, 2]))\n",
    "b2 = tf.Variable(tf.random.normal([2]))\n",
    "\n",
    "w3 = tf.Variable(tf.random.normal([2, 1]))\n",
    "b3 = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+tf.exp(-x))\n",
    "@tf.function\n",
    "def perceptron(x):\n",
    "    hidden = sigmoid(tf.matmul(x, w1) + b1)\n",
    "    hidden2 = sigmoid(tf.matmul(hidden, w2) + b2)\n",
    "    return sigmoid(tf.matmul(hidden2, w3) + b3)\n",
    "@tf.function\n",
    "def loss_fn(y_true, y_pred):\n",
    "    return tf.reduce_mean(-(y_true * tf.math.log(y_pred) + (1 - y_true)*tf.math.log(1 -y_pred)))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.5)\n",
    "\n",
    "def binary_output(x):\n",
    "    return int(x.numpy()[0][0] > 0.5)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct_prediction = tf.equal(tf.cast(y_pred > 0.5, tf.float32), y_true)\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#tensorboard 로그 저장 경로\n",
    "stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = f'logs/mylogs/{stamp}'\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "#Tensorboard 그래프 추적 및 로그저장\n",
    "tf.summary.trace_off()\n",
    "tf.summary.trace_on(graph=True)\n",
    "pred_initial = perceptron(x)\n",
    "_ = loss_fn(y, pred_initial)\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(name=\"graph_trace\", step=0)\n",
    "print(f\"로그저장 -> {logdir}\")\n",
    "\n",
    "for epoch in range(5000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = perceptron(x)\n",
    "        loss = loss_fn(y, pred)\n",
    "    gradients = tape.gradient(loss, [w1, b1, w2,b2, w3, b3])\n",
    "    optimizer.apply_gradients(zip(gradients, [w1, b1, w2,b2, w3, b3]))\n",
    "\n",
    "    acc_val = accuracy(y, pred)\n",
    "\n",
    "    with writer.as_default():\n",
    "        tf.summary.scalar(\"Loss\", loss, step=epoch)\n",
    "        tf.summary.scalar(\"Accuracy\", acc_val, step=epoch)\n",
    "        \n",
    "    if (epoch+1) %500 == 0:\n",
    "        w1_val = np.squeeze(w1.numpy())\n",
    "        b1_val = np.squeeze(b1.numpy())\n",
    "        w2_val = np.squeeze(w2.numpy())\n",
    "        b2_val = np.squeeze(b2.numpy())\n",
    "        w3_val = np.squeeze(w3.numpy())\n",
    "        b3_val = np.squeeze(b3.numpy())\n",
    "        print(f\"step = {epoch+1}, cost = {loss.numpy():.9f}\")\n",
    "        print(f\"w = {w1_val}, b = {b1_val}\")\n",
    "        print(f\"w = {w2_val}, b = {b2_val}\")\n",
    "        print(f\"w = {w3_val}, b = {b3_val}\")\n",
    "for input_data in x:\n",
    "    prediction = perceptron(np.array([input_data], dtype=np.float32))\n",
    "    print(f\"입력: {input_data.tolist()}, 예측(확률): {prediction.numpy()[0][0]:.4f}, 예측(이진): {binary_output(prediction)}\")\n",
    "#최종 정확도\n",
    "predictions = perceptron(x)\n",
    "acc = accuracy(y, predictions)\n",
    "print(f\"정확도: {acc.numpy():.4f}\")\n",
    "#수정된 변수명 출력\n",
    "print(f\"TensorBoard 로그 저장 경로: {logdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c3ab812-d2d2-4a39-a3d3-80c5b25c3b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. conda info --envs\\n2. conda activate base\\n3. tensorboard --logdir=/Users/admin/anaconda_projects/ict_projects/logs/mylogs\\n4. open http://localhost:6006/\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensorboard\n",
    "\"\"\"\n",
    "1. conda info --envs\n",
    "2. conda activate base\n",
    "3. tensorboard --logdir=/Users/admin/anaconda_projects/ict_projects/logs/mylogs\n",
    "4. open http://localhost:6006/\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
