{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c777a699-e96e-423e-924d-490e117cea2c",
   "metadata": {},
   "source": [
    "When we differentiate Sigmoid, ~0.25 is the max value we can get. This causes **Vanishing Gradient** problem, \n",
    "which after going through lists of hidden layers (during back propagation) gets infinitely close to 0.\n",
    "\n",
    "Therefore, to solve this problem we use **ReLU**\n",
    "where: \n",
    "\n",
    "- ReLU(x) <= 0, return 0\n",
    "- ReLU(x) > 0, return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b212191f-3046-44a3-af51-7decf000031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, cost = 1.8352, accuracy = 0.7574\n",
      "epoch = 1000, cost = 0.4128, accuracy = 0.8511\n",
      "epoch = 2000, cost = 0.4071, accuracy = 0.8511\n",
      "epoch = 3000, cost = 0.4032, accuracy = 0.8511\n",
      "epoch = 4000, cost = 0.3985, accuracy = 0.8511\n",
      "epoch = 5000, cost = 0.3958, accuracy = 0.8532\n",
      "epoch = 6000, cost = 0.3921, accuracy = 0.8574\n",
      "epoch = 7000, cost = 0.3938, accuracy = 0.8574\n",
      "epoch = 8000, cost = 0.3874, accuracy = 0.8532\n",
      "epoch = 9000, cost = 0.3829, accuracy = 0.8574\n",
      "epoch = 10000, cost = 0.3788, accuracy = 0.8553\n",
      "\n",
      " Final Accuracy: 0.8553\n",
      "\n",
      "New Data Prediction (Probability): [[0.1960173]]\n",
      "New Data Predicted Class: [[0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# load data\n",
    "data_set = np.loadtxt(\"ThoraricSurgery.csv\", delimiter=\",\")\n",
    "x_data = data_set[:, 0:17].astype(np.float32)\n",
    "y_data = data_set[:, [17]].astype(np.float32)\n",
    "\n",
    "# set weights & bias\n",
    "w1 = tf.Variable(tf.random.normal([17, 30]))\n",
    "b1 = tf.Variable(tf.random.normal([30]))\n",
    "w2 = tf.Variable(tf.random.normal([30, 1]))\n",
    "b2 = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "# forward prop\n",
    "def forward(x):\n",
    "    hidden = tf.sigmoid(tf.matmul(x, w1) + b1)\n",
    "    hypothesis = tf.sigmoid(tf.matmul(hidden, w2) + b2)\n",
    "    return hypothesis\n",
    "\n",
    "# loss func\n",
    "def loss_fn(x, y):\n",
    "    hypothesis = forward(x)\n",
    "    cost = -tf.reduce_mean(y * tf.math.log(hypothesis + 1e-7) + \n",
    "                           (1 - y) * tf.math.log(1 - hypothesis + 1e-7))\n",
    "    return cost\n",
    "\n",
    "# acc func\n",
    "def accuracy(y_true, y_pred):\n",
    "    predicted_class = tf.cast(y_pred > 0.5, dtype=tf.float32)\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_true, predicted_class), dtype=tf.float32))\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "# train\n",
    "for epoch in range(10001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(x_data, y_data)\n",
    "    gradients = tape.gradient(loss, [w1, b1, w2, b2])\n",
    "    optimizer.apply_gradients(zip(gradients, [w1, b1, w2, b2]))\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        pred = forward(x_data)\n",
    "        acc_val = accuracy(y_data, pred)\n",
    "        print(f\"epoch = {epoch}, cost = {loss.numpy():.4f}, accuracy = {acc_val.numpy():.4f}\")\n",
    "\n",
    "# final Acc\n",
    "predictions = forward(x_data)\n",
    "predicted_class = tf.cast(predictions > 0.5, dtype=tf.float32)\n",
    "acc = tf.reduce_mean(tf.cast(tf.equal(predicted_class, y_data), dtype=tf.float32))\n",
    "print(f\"\\n Final Accuracy: {acc.numpy():.4f}\")\n",
    "\n",
    "# Pred New Data\n",
    "new_data = np.array([[132, 2, 2.12, 1.72, 1, 0, 0, 0, 0, 0, 12, 0, 0, 0, 1, 0, 74]], dtype=np.float32)\n",
    "new_prediction = forward(new_data)\n",
    "new_predicted_class = tf.cast(new_prediction > 0.5, dtype=tf.float32)\n",
    "\n",
    "print(\"\\nNew Data Prediction (Probability):\", new_prediction.numpy())\n",
    "print(\"New Data Predicted Class:\", new_predicted_class.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
