{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f5f710-020e-44ac-b205-bd1682b0e55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (0, 0) Output: 0\n",
      "Input: (1, 0) Output: 1\n",
      "Input: (0, 1) Output: 1\n",
      "Input: (1, 1) Output: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w11 = np.array([-2, -2])\n",
    "w12 = np.array([2, 2])\n",
    "w2 = np.array([1, 1])\n",
    "b1 = 3\n",
    "b2 = -1\n",
    "b3 = -1\n",
    "\n",
    "def MLP(x, w, b):\n",
    "    y = np.sum(w * x) + b\n",
    "    if y <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def NAND(x1, x2):\n",
    "    return MLP(np.array([x1, x2]), w11, b1)\n",
    "\n",
    "def OR(x1, x2):\n",
    "    return MLP(np.array([x1, x2]), w12, b2)\n",
    "\n",
    "def AND(x1, x2):\n",
    "    return MLP(np.array([x1, x2]), w2, b3)\n",
    "\n",
    "def XOR(x1, x2):\n",
    "    return AND(NAND(x1, x2), OR(x1, x2))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for x in [(0, 0), (1, 0), (0, 1), (1, 1)]:\n",
    "        y = XOR(x[0], x[1])\n",
    "        print(\"Input: \" + str(x) + \" Output: \" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "030191fb-58b8-4618-9baa-d6f40bcb1fa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 21:03:40.043118: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 500, cost = 0.703790307, w = [0.51884794 0.06409978], b = -0.16101372241973877\n",
      "step = 1000, cost = 0.697289169, w = [0.3622901  0.02921341], b = -0.2066900134086609\n",
      "step = 1500, cost = 0.695655227, w = [0.2767561  0.03295634], b = -0.18026258051395416\n",
      "step = 2000, cost = 0.694711685, w = [0.21569085 0.03728088], b = -0.14960385859012604\n",
      "step = 2500, cost = 0.694134712, w = [0.16913933 0.03859998], b = -0.12316592037677765\n",
      "step = 3000, cost = 0.693777144, w = [0.13311978 0.03761426], b = -0.10126187652349472\n",
      "step = 3500, cost = 0.693552732, w = [0.10510145 0.03523072], b = -0.08323230594396591\n",
      "step = 4000, cost = 0.693410456, w = [0.08322831 0.03211305], b = -0.06840873509645462\n",
      "step = 4500, cost = 0.693319261, w = [0.06609616 0.02870237], b = -0.05622385814785957\n",
      "step = 5000, cost = 0.693260431, w = [0.05263427 0.02527872], b = -0.04620874300599098\n",
      "step = 5500, cost = 0.693221986, w = [0.04202313 0.02201118], b = -0.037977274507284164\n",
      "step = 6000, cost = 0.693196774, w = [0.03363349 0.01899383], b = -0.031211934983730316\n",
      "step = 6500, cost = 0.693180203, w = [0.02698086 0.01627127], b = -0.025651682168245316\n",
      "step = 7000, cost = 0.693169236, w = [0.02169074 0.01385619], b = -0.021081894636154175\n",
      "step = 7500, cost = 0.693161964, w = [0.01747282 0.01174149], b = -0.017326166853308678\n",
      "step = 8000, cost = 0.693157077, w = [0.01410126 0.00990852], b = -0.014239512383937836\n",
      "step = 8500, cost = 0.693153858, w = [0.01139981 0.00833261], b = -0.011702723801136017\n",
      "step = 9000, cost = 0.693151653, w = [0.00923043 0.00698663], b = -0.00961785577237606\n",
      "step = 9500, cost = 0.693150163, w = [0.00748471 0.00584326], b = -0.00790440570563078\n",
      "step = 10000, cost = 0.693149209, w = [0.0060772  0.00487637], b = -0.006496216636151075\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = np.array([[0,0],[0, 1],[1, 0],[1, 1]], dtype = np.float32)\n",
    "y = np.array([[0], [1],[1], [0]], dtype = np.float32)\n",
    "\n",
    "w = tf.Variable(tf.random.uniform([2, 1], dtype = np.float32))\n",
    "b = tf.Variable(tf.random.uniform([1], dtype = np.float32))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+tf.exp(-x))\n",
    "\n",
    "def perceptron(x):\n",
    "    return sigmoid(tf.matmul(x, w) + b)\n",
    "\n",
    "def cost(y_true, y_pred):\n",
    "    return tf.reduce_mean(-(y_true * tf.math.log(y_pred) + (1 - y_true)*tf.math.log(1 -y_pred)))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01)\n",
    "\n",
    "def binary_output(x):\n",
    "    return int(x.numpy()[0][0] > 0.5)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct_prediction = tf.equal(tf.cast(y_pred > 0.5, tf.float32), y_true)\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "for epoch in range(10000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = perceptron(x)\n",
    "        loss = cost(y, pred)\n",
    "    gradients = tape.gradient(loss, [w,b])\n",
    "    optimizer.apply_gradients(zip(gradients, [w,b]))\n",
    "\n",
    "    if (epoch+1) %500 == 0:\n",
    "        w_val = np.squeeze(w.numpy())\n",
    "        b_val = np.squeeze(b.numpy())\n",
    "        print(f\"step = {epoch+1}, cost = {loss.numpy():.9f}, w = {w_val}, b = {b_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f17ba1f9-4526-4cf7-9798-326663cd2b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] [[0.49837536]\n",
      " [0.49959484]\n",
      " [0.49989524]\n",
      " [0.5011148 ]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(y, pred).numpy())\n",
    "print(y, pred.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
