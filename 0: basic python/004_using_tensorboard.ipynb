{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3aee6d-96ef-4aea-8d70-5c8c77e0c6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. conda info --envs\\n2. conda activate base\\n3. tensorboard --logdir=./~mylogs\\n4. open http://localhost:6006/\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensorboard\n",
    "\"\"\"\n",
    "1. conda info --envs\n",
    "2. conda activate base\n",
    "3. tensorboard --logdir=./~mylogs\n",
    "4. open http://localhost:6006/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd4264f2-3667-4dbc-bf36-21b589630031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 00:04:14.464412: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log saved -> logs/mylogs/20250507-000420\n",
      "step = 500, cost = 0.680882215\n",
      "w = [[-0.78266335 -1.4110566 ]\n",
      " [-0.52949774  1.1748805 ]], b = [-0.19011432  1.5371673 ]\n",
      "w = [[-0.16363601  0.26892635]\n",
      " [-1.4252124   0.77568686]], b = [0.10529738 0.5206397 ]\n",
      "w = [ 1.637362  -1.3991512], b = 0.6424564123153687\n",
      "step = 1000, cost = 0.510709465\n",
      "w = [[-0.96508104 -3.9975019 ]\n",
      " [-1.033962    4.4686246 ]], b = [-0.36387217  2.5336547 ]\n",
      "w = [[-0.33569017  0.3867107 ]\n",
      " [-4.123049    2.1699014 ]], b = [ 1.4336555  -0.32731846]\n",
      "w = [ 4.3774834 -2.306686 ], b = 1.0803422927856445\n",
      "step = 1500, cost = 0.467125982\n",
      "w = [[-0.8383455 -4.8056555]\n",
      " [-2.3190737  5.632705 ]], b = [-0.11207987  3.4285545 ]\n",
      "w = [[-1.0604297  1.3521061]\n",
      " [-4.7671714  2.0452023]], b = [ 2.2080424 -1.0479528]\n",
      "w = [ 5.483683  -2.9054606], b = 1.2337948083877563\n",
      "step = 2000, cost = 0.126198471\n",
      "w = [[ 2.217181 -5.413704]\n",
      " [-3.137639  6.840512]], b = [1.5515332 3.4859676]\n",
      "w = [[-1.9492263  3.1854181]\n",
      " [-4.17587    1.6521438]], b = [ 4.118602  -2.6866682]\n",
      "w = [ 7.0062437 -5.2416873], b = 0.6456343531608582\n",
      "step = 2500, cost = 0.011910528\n",
      "w = [[ 4.0418186 -6.0791597]\n",
      " [-4.016298   6.9805436]], b = [2.0774524 3.235627 ]\n",
      "w = [[-3.4755886  3.664156 ]\n",
      " [-4.261892   2.3699658]], b = [ 5.4061203 -3.9666712]\n",
      "w = [ 8.798241  -7.0489874], b = 0.28304001688957214\n",
      "step = 3000, cost = 0.005725903\n",
      "w = [[ 4.353906  -6.2377086]\n",
      " [-4.2966847  7.0346446]], b = [2.2104306 3.23164  ]\n",
      "w = [[-3.8247733  3.7345552]\n",
      " [-4.3822966  2.7295053]], b = [ 5.7655034 -4.3545065]\n",
      "w = [ 9.387103  -7.6391354], b = 0.15833565592765808\n",
      "step = 3500, cost = 0.003698191\n",
      "w = [[ 4.5201735 -6.321019 ]\n",
      " [-4.451326   7.068734 ]], b = [2.2833898 3.2402728]\n",
      "w = [[-4.0164657  3.789089 ]\n",
      " [-4.4567404  2.9335046]], b = [ 5.9721913 -4.5786247]\n",
      "w = [ 9.738415 -7.993932], b = 0.08989017456769943\n",
      "step = 4000, cost = 0.002711574\n",
      "w = [[ 4.631207 -6.376358]\n",
      " [-4.555733  7.093597]], b = [2.3328454 3.2497685]\n",
      "w = [[-4.1455965  3.8338757]\n",
      " [-4.511553   3.072498 ]], b = [ 6.1157746 -4.7350254]\n",
      "w = [ 9.989268 -8.247083], b = 0.0446886345744133\n",
      "step = 4500, cost = 0.002132696\n",
      "w = [[ 4.713625  -6.417353 ]\n",
      " [-4.6336226  7.113148 ]], b = [2.3699143 3.2585886]\n",
      "w = [[-4.241727   3.8718815]\n",
      " [-4.5552454  3.176647 ]], b = [ 6.2251663 -4.8546295]\n",
      "w = [10.184508 -8.443703], b = 0.011724844574928284\n",
      "step = 5000, cost = 0.001753717\n",
      "w = [[ 4.778695  -6.4497094]\n",
      " [-4.695291   7.1292524]], b = [2.3993886 3.266553 ]\n",
      "w = [[-4.317688   3.9049008]\n",
      " [-4.5916986  3.2593222]], b = [ 6.3132157 -4.951199 ]\n",
      "w = [10.344385 -8.604381], b = -0.013836235739290714\n",
      "Input: [0.0, 0.0], Prediction(%): 0.0020, Prediction(Binary): 0\n",
      "Input: [0.0, 1.0], Prediction(%): 0.9983, Prediction(Binary): 1\n",
      "Input: [1.0, 0.0], Prediction(%): 0.9984, Prediction(Binary): 1\n",
      "Input: [1.0, 1.0], Prediction(%): 0.0017, Prediction(Binary): 0\n",
      "Acc: 1.0000\n",
      "log saving path - TensorBoard: logs/mylogs/20250507-000420\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "x = np.array([[0,0],[0, 1],[1, 0],[1, 1]], dtype = np.float32)\n",
    "y = np.array([[0], [1], [1], [0]], dtype = np.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random.normal([2, 2]))\n",
    "b1 = tf.Variable(tf.random.normal([2]))\n",
    "\n",
    "w2 = tf.Variable(tf.random.normal([2, 2]))\n",
    "b2 = tf.Variable(tf.random.normal([2]))\n",
    "\n",
    "w3 = tf.Variable(tf.random.normal([2, 1]))\n",
    "b3 = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+tf.exp(-x))\n",
    "@tf.function\n",
    "def perceptron(x):\n",
    "    hidden = sigmoid(tf.matmul(x, w1) + b1)\n",
    "    hidden2 = sigmoid(tf.matmul(hidden, w2) + b2)\n",
    "    return sigmoid(tf.matmul(hidden2, w3) + b3)\n",
    "@tf.function\n",
    "def loss_fn(y_true, y_pred):\n",
    "    return tf.reduce_mean(-(y_true * tf.math.log(y_pred) + (1 - y_true)*tf.math.log(1 -y_pred)))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.5)\n",
    "\n",
    "def binary_output(x):\n",
    "    return int(x.numpy()[0][0] > 0.5)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct_prediction = tf.equal(tf.cast(y_pred > 0.5, tf.float32), y_true)\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#Log save path - tensorboard\n",
    "stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = f'logs/mylogs/{stamp}'\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "#Graph tracking and log saving - tensorboard\n",
    "tf.summary.trace_off()\n",
    "tf.summary.trace_on(graph=True)\n",
    "pred_initial = perceptron(x)\n",
    "_ = loss_fn(y, pred_initial)\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(name=\"graph_trace\", step=0)\n",
    "print(f\"log saved -> {logdir}\")\n",
    "\n",
    "for epoch in range(5000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = perceptron(x)\n",
    "        loss = loss_fn(y, pred)\n",
    "    gradients = tape.gradient(loss, [w1, b1, w2,b2, w3, b3])\n",
    "    optimizer.apply_gradients(zip(gradients, [w1, b1, w2,b2, w3, b3]))\n",
    "\n",
    "    acc_val = accuracy(y, pred)\n",
    "\n",
    "    with writer.as_default():\n",
    "        tf.summary.scalar(\"Loss\", loss, step=epoch)\n",
    "        tf.summary.scalar(\"Accuracy\", acc_val, step=epoch)\n",
    "        \n",
    "    if (epoch+1) %500 == 0:\n",
    "        w1_val = np.squeeze(w1.numpy())\n",
    "        b1_val = np.squeeze(b1.numpy())\n",
    "        w2_val = np.squeeze(w2.numpy())\n",
    "        b2_val = np.squeeze(b2.numpy())\n",
    "        w3_val = np.squeeze(w3.numpy())\n",
    "        b3_val = np.squeeze(b3.numpy())\n",
    "        print(f\"step = {epoch+1}, cost = {loss.numpy():.9f}\")\n",
    "        print(f\"w = {w1_val}, b = {b1_val}\")\n",
    "        print(f\"w = {w2_val}, b = {b2_val}\")\n",
    "        print(f\"w = {w3_val}, b = {b3_val}\")\n",
    "for input_data in x:\n",
    "    prediction = perceptron(np.array([input_data], dtype=np.float32))\n",
    "    print(f\"Input: {input_data.tolist()}, Prediction(%): {prediction.numpy()[0][0]:.4f}, Prediction(Binary): {binary_output(prediction)}\")\n",
    "\n",
    "#Final Acc\n",
    "predictions = perceptron(x)\n",
    "acc = accuracy(y, predictions)\n",
    "print(f\"Acc: {acc.numpy():.4f}\")\n",
    "\n",
    "#log saved\n",
    "print(f\"log saving path - TensorBoard: {logdir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
